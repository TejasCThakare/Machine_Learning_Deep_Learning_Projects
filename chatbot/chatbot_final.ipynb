{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q2tVUIOPT87z"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Open the 'Intent.json' file and load its contents as a JSON object\n",
        "with open('Intent.json') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Initialize empty lists to store training sentences, labels, unique labels, and responses\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "labels = []\n",
        "responses = []\n",
        "\n",
        "# Loop through each intent in the JSON data\n",
        "for intent in data['intents']:\n",
        "    # Loop through each pattern in the current intent's patterns\n",
        "    for pattern in intent['patterns']:\n",
        "        # Add the pattern to the list of training sentences\n",
        "        training_sentences.append(pattern)\n",
        "        # Add the intent's tag to the list of training labels\n",
        "        training_labels.append(intent['tag'])\n",
        "\n",
        "    # Add the list of responses for the current intent to the responses list\n",
        "    responses.append(intent['responses'])\n",
        "\n",
        "    # If the intent's tag is not already in the list of labels, add it\n",
        "    if intent['tag'] not in labels:\n",
        "        labels.append(intent['tag'])\n",
        "\n",
        "# Calculate the number of unique labels (classes)\n",
        "num_classes = len(labels)\n"
      ],
      "metadata": {
        "id": "kM1TKdLEUpoo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the LabelEncoder\n",
        "lbl_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the LabelEncoder with the training labels\n",
        "lbl_encoder.fit(training_labels)\n",
        "\n",
        "# Transform the training labels into encoded numeric values\n",
        "training_labels = lbl_encoder.transform(training_labels)\n"
      ],
      "metadata": {
        "id": "2nRSIxJ1V5Gg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define parameters for the tokenizer and padding\n",
        "vocab_size = 1000         # Maximum number of words to keep in the vocabulary\n",
        "embedding_dim = 16        # Dimension of the embedding vectors\n",
        "max_len = 20              # Maximum length of the sequences\n",
        "oov_token = \"<OOV>\"       # Token for out-of-vocabulary words\n",
        "\n",
        "# Initialize the Tokenizer with the specified vocabulary size and OOV token\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
        "\n",
        "# Fit the tokenizer on the training sentences\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "# Retrieve the word index that maps words to their indices\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Convert the training sentences into sequences of integers\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "\n",
        "# Pad the sequences to ensure they all have the same length\n",
        "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)\n"
      ],
      "metadata": {
        "id": "vI25-kyAWPTU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()  #The Sequential model is a linear stack of layers.\n",
        "\n",
        "# Add an Embedding layer\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "\n",
        "# Add a GlobalAveragePooling1D layer\n",
        "model.add(GlobalAveragePooling1D())\n",
        "\n",
        "# Add the first Dense layer with ReLU activation\n",
        "model.add(Dense(16, activation='relu'))\n",
        "\n",
        "# Add the second Dense layer with ReLU activation\n",
        "model.add(Dense(16, activation='relu'))\n",
        "\n",
        "# Add the output Dense layer with softmax activation\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Set the number of epochs\n",
        "epochs = 500\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)\n"
      ],
      "metadata": {
        "id": "BMDIPUufgQ2C",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Save the trained model\n",
        "model.save(\"chat_model\")  # Save the entire model to 'chat_model'\n",
        "\n",
        "# Save the fitted tokenizer\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    # 'tokenizer' is saved to 'tokenizer.pickle'\n",
        "\n",
        "# Save the fitted label encoder\n",
        "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
        "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    # 'lbl_encoder' is saved to 'label_encoder.pickle'\n"
      ],
      "metadata": {
        "id": "2kY2moFgiOBE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colorama\n",
        "colorama.init()\n",
        "from colorama import Fore, Style\n",
        "import random\n",
        "\n",
        "\n",
        "# Load the intents data from a JSON file\n",
        "with open(\"Intent.json\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "def chat():\n",
        "    # Load the trained model from file\n",
        "    model = keras.models.load_model('chat_model')\n",
        "\n",
        "    # Load the tokenizer object from file\n",
        "    with open('tokenizer.pickle', 'rb') as handle:\n",
        "        tokenizer = pickle.load(handle)\n",
        "\n",
        "    # Load the label encoder object from file\n",
        "    with open('label_encoder.pickle', 'rb') as enc:\n",
        "        lbl_encoder = pickle.load(enc)\n",
        "\n",
        "    # Set the maximum length for input sequences\n",
        "    max_len = 20\n",
        "\n",
        "    while True:\n",
        "        # Prompt user for input and display the prompt in light blue\n",
        "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
        "        inp = input()\n",
        "\n",
        "        # Exit the loop if the user types \"quit\"\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        # Convert user input to sequences and pad them to max_len\n",
        "        result = model.predict(keras.preprocessing.sequence.pad_sequences(\n",
        "            tokenizer.texts_to_sequences([inp]),\n",
        "            truncating='post', maxlen=max_len))\n",
        "\n",
        "        # Get the predicted tag from the result\n",
        "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
        "\n",
        "        # Find the appropriate response based on the predicted tag\n",
        "        for i in data['intents']:\n",
        "            if i['tag'] == tag:\n",
        "                # Print the response in green color\n",
        "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL, np.random.choice(i['responses']))\n",
        "\n",
        "# Print the initial message in yellow to inform the user about starting the chat\n",
        "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
        "\n",
        "# Call the chat function to start the interactive chat session\n",
        "chat()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypEO-f1xiTcI",
        "outputId": "16f65fff-d9d9-4745-ee15-5ce9f95d7d7e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start messaging with the bot (type quit to stop)!\n",
            "User: hey there\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "ChatBot: Hello\n",
            "User: who are you\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "ChatBot: I.m Joana, your bot assistant\n",
            "User: i need help!\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "ChatBot: Yes Sure, How can I support you\n",
            "User: i want to create account\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "ChatBot: Just go to our web site and follow the guidelines to create a new account\n",
            "User: okay\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "ChatBot: Thanks\n",
            "User: quit\n"
          ]
        }
      ]
    }
  ]
}