{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Here is the implementation of autocorrect system for suggesting the possible correct spelling or correcting the spelling mistake. Here I used the NLTK Library and machine learning for predicting the correct spelling for the given input word.**"
      ],
      "metadata": {
        "id": "6grdb7tdnJPv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kPSbRXamgUa9"
      },
      "outputs": [],
      "source": [
        "import re   # importing regular expression\n",
        "\n",
        "# words\n",
        "w = []  #Initialising to store the word\n",
        "\n",
        "# reading text file\n",
        "with open('data.txt', 'r', encoding=\"utf8\") as f: # open the data.text file in read mode\n",
        "\tfile_name_data = f.read() #Real the content of the file\n",
        "\tfile_name_data = file_name_data.lower() #converts the entire dataset in lower case\n",
        "\tw = re.findall('\\w+', file_name_data) #Uses the re.findall function to find all sequences of word characters\n",
        "\t                                      # (letters, digits, and underscores) in the text.\n",
        "                                        # The result is a list of words stored in w\n",
        "\n",
        "# vocabulary\n",
        "main_set = set(w) # Unique vocabulary of data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(main_set) # Checking"
      ],
      "metadata": {
        "id": "ZRNq_Ko-BBBv"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the frequency of words in the entire data.txt file\n",
        "def counting_words(words):\n",
        "\tword_count = {}\n",
        "\tfor word in words:\n",
        "\t\tif word in word_count:\n",
        "\t\t\tword_count[word] += 1\n",
        "\t\telse:\n",
        "\t\t\tword_count[word] = 1\n",
        "\treturn word_count\n"
      ],
      "metadata": {
        "id": "hYvULlHhgz19"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the probability of each word\n",
        "def prob_cal(word_count_dict):\n",
        "\tprobs = {}\n",
        "\tm = sum(word_count_dict.values())\n",
        "\tfor key in word_count_dict.keys():\n",
        "\t\tprobs[key] = word_count_dict[key] / m\n",
        "\treturn probs\n"
      ],
      "metadata": {
        "id": "5qWjpLUtjBV6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to create all types of different words possible, Following methods has to be used:\n",
        "\n",
        "1.   Lemmatization\n",
        "2.   Deletion of letter\n",
        "3.   Switching Letter\n",
        "4.   Replace Letter\n",
        "5.   Insert new Letter\n",
        "\n"
      ],
      "metadata": {
        "id": "Kiupj2PoSNrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pattern # To do Lemmatization"
      ],
      "metadata": {
        "id": "eEIBlPhzSAIz"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LemmWord: extracting and adding\n",
        "# root word i.e.Lemma using pattern module\n",
        "import pattern\n",
        "from pattern.en import lemma, lexeme\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "def LemmWord(word): #This function splits each word from the given input string\n",
        "\treturn list(lexeme(wd) for wd in word.split())[0] #lexeme function gives different forms of the word and return first element in the list\n"
      ],
      "metadata": {
        "id": "OVxjV9x-jWBp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting letters from the words\n",
        "def DeleteLetter(word):\n",
        "\tdelete_list = [] # This list has stored the entire document in form of lists, removing the ith character from the original data.txt\n",
        "\tsplit_list = [] # list of tuple\n",
        "\n",
        "\n",
        "\tfor i in range(len(word)): #For each index i, a tuple is created containing two parts:\n",
        "\t                        \t#the substring from the start of the word to the i-th character (word[0:i]) and\n",
        "\t                         \t#the substring from the i-th character to the end (word[i:]).\n",
        "\t\tsplit_list.append((word[0:i], word[i:]))\n",
        "\n",
        "\n",
        "\tfor a, b in split_list: #loop iterates over each tuple (a, b) in split_list.\n",
        "\t\tdelete_list.append(a + b[1:]) #For each tuple, it concatenates the first part a and the second part b\n",
        "\t\t                              #excluding its first character (b[1:]),\n",
        "\t#effectively removing the i-th character from the original word.\n",
        "\treturn delete_list\n"
      ],
      "metadata": {
        "id": "0tbJP1h9jsnA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(DeleteLetter('sky')) # Checking"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LTvuw4G7Y9y",
        "outputId": "7028d271-5aed-4c21-e936-05cc79bdeff1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splited list: [('', 'sky'), ('s', 'ky'), ('sk', 'y')]\n",
            "Delete operation :\n",
            "['ky', 'sy', 'sk']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Switching two letters in a word\n",
        "def Switch_(word):\n",
        "\tsplit_list = []\n",
        "\tswitch_l = []\n",
        "\n",
        "\t#creating pair of the words(and breaking them)\n",
        "\tfor i in range(len(word)):\n",
        "\t\tsplit_list.append((word[0:i], word[i:]))\n",
        "\n",
        "\t#Printint the first word (i.e. a)\n",
        "\t#then replacing the first and second character of b\n",
        "\tswitch_l = [a + b[1] + b[0] + b[2:] for a, b in split_list if len(b) >= 2] #it switches the first and 2nd letter of word in b while keeping rest letters in b as it is\n",
        "\treturn switch_l\n"
      ],
      "metadata": {
        "id": "t_TpQDCLjvTI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Replace_(word):\n",
        "\tsplit_l = []\n",
        "\treplace_list = []\n",
        "\n",
        "\t# Replacing the letter one-by-one from the list of alphs\n",
        "\tfor i in range(len(word)):\n",
        "\t\tsplit_l.append((word[0:i], word[i:]))\n",
        "\talphs = 'abcdefghijklmnopqrstuvwxyz'\n",
        "\t#For each tuple and each letter l in alphs, it concatenates the first  a,\n",
        "\t# the letter l, and the remaining part of b excluding its first letter\n",
        "\treplace_list = [a + l + (b[1:] if len(b) > 1 else '')\n",
        "\t\t\t\t\tfor a, b in split_l if b for l in alphs] #The condition if b ensures that b is not empty.\n",
        "\treturn replace_list\n"
      ],
      "metadata": {
        "id": "KU82k3Vrj1MK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_(word):\n",
        "\tsplit_l = []\n",
        "\tinsert_list = []\n",
        "\n",
        "\t# Making pairs of the split words\n",
        "\tfor i in range(len(word) + 1):\n",
        "\t\tsplit_l.append((word[0:i], word[i:]))\n",
        "\n",
        "\t#For each tuple and each letter l in alphs,\n",
        "\t#it concatenates the first part a, the letter l, and the second part b.\n",
        "\talphs = 'abcdefghijklmnopqrstuvwxyz'\n",
        "\tinsert_list = [a + l + b for a, b in split_l for l in alphs]\n",
        "\treturn insert_list\n"
      ],
      "metadata": {
        "id": "zMolKWikk1Bk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collecting all the words\n",
        "# in a set(so that no word will repeat)\n",
        "def colab_1(word, allow_switches=True):\n",
        "\tcolab_1 = set()\n",
        " #Applying all edit options\n",
        "\tcolab_1.update(DeleteLetter(word))\n",
        "\tif allow_switches:\n",
        "\t\tcolab_1.update(Switch_(word))\n",
        "\tcolab_1.update(Replace_(word))\n",
        "\tcolab_1.update(insert_(word))\n",
        "\treturn colab_1\n",
        "\n",
        "# collecting words using by allowing switches\n",
        "def colab_2(word, allow_switches=True):\n",
        "\tcolab_2 = set()\n",
        "\t#edit_one is set to the result of colab_1, containing variations of the original word after one level of edits.\n",
        "\tedit_one = colab_1(word, allow_switches=allow_switches)\n",
        " #For each word w in edit_one, the function generates further variations by applying colab_1 to w.\n",
        " #This effectively performs two levels of edits on the original word.\n",
        "\tfor w in edit_one:\n",
        "\t\tif w:\n",
        "\t\t\tedit_two = colab_1(w, allow_switches=allow_switches)\n",
        "\t\t\tcolab_2.update(edit_two)\n",
        "\treturn colab_2\n"
      ],
      "metadata": {
        "id": "1-hrrcTkk--e"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only storing those values which are in the vocab\n",
        "def get_corrections(word, probs, vocab, n=2):\n",
        "\tsuggested_word = []\n",
        "\tbest_suggestion = []\n",
        "\t# Now suggested_word list contains all the possible variation of the word.\n",
        "\t# if a word is not in vocab then it creates level 1 variation with the intersection with\n",
        "\t# vocab and check and if it still does not create or find any valid word then it creates another level 2 variation of a word\n",
        "\t# with intersection with vocab and check if it get any valid word.\n",
        "\tsuggested_word = list(\n",
        "\t\t(word in vocab and word) or colab_1(word).intersection(vocab)\n",
        "\t\tor colab_2(word).intersection(\n",
        "\t\t\tvocab))\n",
        "\n",
        "\t# finding out the words with high frequencies\n",
        "\tbest_suggestion = [[s, probs[s]] for s in list(reversed(suggested_word))]\n",
        "\treturn best_suggestion\n"
      ],
      "metadata": {
        "id": "5sQSdpGBlCKH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input\n",
        "my_word = input(\"Input the word : \")\n",
        "\n",
        "print(\"The suggestions are: \")\n",
        "print(end='\\n')\n",
        "\n",
        "# Counting word function\n",
        "word_count = counting_words(main_set)\n",
        "\n",
        "# Calculating probability\n",
        "probs = prob_cal(word_count)\n",
        "\n",
        "# only storing correct words\n",
        "tmp_corrections = get_corrections(my_word, probs, main_set, 2)\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "\tif(i < 3):\n",
        "\t\tprint(word_prob[0])\n",
        "\telse:\n",
        "\t\tbreak\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM1oidOllHMO",
        "outputId": "781b7742-932a-4b2d-87e5-b33c8a24873f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input the word : masimub\n",
            "The suggestions are: \n",
            "\n",
            "maximum\n",
            "maximus\n"
          ]
        }
      ]
    }
  ]
}